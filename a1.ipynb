{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "from numba import jit\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "First, let’s document the degree to which we can speed up the compute time of a program as we (pre-)compile computationally intensive portions of the code using numba.\n",
    "\n",
    "a. (3 points) Rewrite this computationally intensive portion of the code as a separate function (returning z_mat) and compile it using the numba @jit decorator. Incorporate the function into the program above and compare how long it takes to run the original version of the code (as it is written above) with the time it takes to run your @jit-accelerated version. Report the speedup you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original nested loop function\n",
    "def loop_original(eps_mat, z_mat, rho, mu, z_0, T, S):\n",
    "    for s_ind in range(S):\n",
    "        z_tm1 = z_0\n",
    "        for t_ind in range(T):\n",
    "            e_t = eps_mat[t_ind, s_ind]\n",
    "            z_t = rho * z_tm1 + (1 - rho) * mu + e_t\n",
    "            z_mat[t_ind, s_ind] = z_t\n",
    "            z_tm1 = z_t\n",
    "    \n",
    "    return z_mat\n",
    "\n",
    "# JIT accelerated function\n",
    "@jit(nopython=True)\n",
    "def loop_jit(eps_mat, z_mat, rho, mu, z_0, T, S):\n",
    "    for s_ind in range(S):\n",
    "        z_tm1 = z_0\n",
    "        for t_ind in range(T):\n",
    "            e_t = eps_mat[t_ind, s_ind]\n",
    "            z_t = rho * z_tm1 + (1 - rho) * mu + e_t\n",
    "            z_mat[t_ind, s_ind] = z_t\n",
    "            z_tm1 = z_t\n",
    "    return z_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 833 ms, sys: 503 µs, total: 834 ms\n",
      "Wall time: 842 ms\n",
      "CPU times: user 118 ms, sys: 9.32 ms, total: 127 ms\n",
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "# Set model parameters\n",
    "rho = 0.5\n",
    "mu = 3.0\n",
    "sigma = 1.0\n",
    "z_0 = mu\n",
    "\n",
    "# Set simulation parameters, draw all idiosyncratic random shocks,\n",
    "# and create empty containers\n",
    "S = 1000  # Set the number of lives to simulate\n",
    "T = 4160  # Set the number of periods for each simulation\n",
    "np.random.seed(25)\n",
    "eps_mat = sts.norm.rvs(loc=0, scale=sigma, size=(T, S))\n",
    "z_mat = np.zeros((T, S))\n",
    "\n",
    "# Time the original function\n",
    "%time ori_results = loop_original(eps_mat, z_mat, rho, mu, z_0, T, S)\n",
    "# Time the JIT-accelerated function\n",
    "%time jit_results = loop_jit(eps_mat, z_mat, rho, mu, z_0, T, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup: 6.58x\n"
     ]
    }
   ],
   "source": [
    "original_time = 842  # Original execution time in milliseconds\n",
    "optimized_time = 128  # Optimized execution time in milliseconds\n",
    "speedup = original_time / optimized_time  # Calculate speedup\n",
    "print(f\"Speedup: {speedup:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. (3 points) Now, pre-compile a version of your function ahead of time using numba. Incorporate this pre-compiled code into the program above and compare how long it takes to run the original version of the code (as it is written above) with the time it takes to run your pre-compiled version. Report the speedup you observe. \n",
    "\n",
    "One hint:\n",
    "Check the data types for each of your variables and make sure you are specifying them correctly in your numba signature. For instance, as defined in the code above, z_mat and eps_mat are 2d arrays that contain 64-bit (8-byte) floats and can thus be represented as f8[:,:] in the signature. Consult the numba documentation on types and signaturesLinks to an external site. for more detail on this notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sg/9v6g6q1n52zgjdgv93fw7stc0000gn/T/ipykernel_31206/2883751853.py:1: NumbaPendingDeprecationWarning: \u001b[1mThe 'pycc' module is pending deprecation. Replacement technology is being developed.\n",
      "\n",
      "Pending Deprecation in Numba 0.57.0. For more information please see: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-the-numba-pycc-module\u001b[0m\n",
      "  from numba.pycc import CC\n",
      "ld: warning: duplicate -rpath '/Users/jessie/anaconda3/lib' ignored\n",
      "ld: warning: object file (/private/var/folders/sg/9v6g6q1n52zgjdgv93fw7stc0000gn/T/pycc-build-test_aot-wdwlsa31/test_aot.cpython-311-darwin.o) was built for newer 'macOS' version (14.0) than being linked (11.1)\n"
     ]
    }
   ],
   "source": [
    "from numba.pycc import CC\n",
    "\n",
    "# name of compiled module to create:\n",
    "cc = CC('test_aot')\n",
    "\n",
    "# Correct the function signature if necessary (using 64-bit floats for all except indices):\n",
    "@cc.export('loop_aot', 'f8[:,:](f8[:,:], f8[:,:], f8, f8, f8, i8, i8)')\n",
    "def loop_aot(eps_mat, z_mat, rho, mu, z_0, T, S):\n",
    "    for s_ind in range(S):  # Loop over each simulation\n",
    "        z_tm1 = z_0  # Set initial value for each simulation\n",
    "        for t_ind in range(T):  # Loop over each time period\n",
    "            e_t = eps_mat[t_ind, s_ind]  # Random shock\n",
    "            z_t = rho * z_tm1 + (1 - rho) * mu + e_t  # Update equation\n",
    "            z_mat[t_ind, s_ind] = z_t  # Store the result\n",
    "            z_tm1 = z_t  # Prepare for next period\n",
    "    return z_mat\n",
    "\n",
    "cc.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                       \u001b[31mtest_aot.cpython-311-darwin.so\u001b[m\u001b[m*\n",
      "a1.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.8 ms, sys: 3.79 ms, total: 21.6 ms\n",
      "Wall time: 21.6 ms\n"
     ]
    }
   ],
   "source": [
    "import test_aot\n",
    "%time aot_result = test_aot.loop_aot(eps_mat, z_mat, rho, mu, z_0, T, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup: 38.98x\n"
     ]
    }
   ],
   "source": [
    "precompiled_time = 21.6  \n",
    "speedup_precompile = original_time / precompiled_time  # Calculate speedup\n",
    "print(f\"Speedup: {speedup_precompile:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. (1 point) How does the pre-compiled code speedup compare to the @jit speedup? With this particular simulation application in mind, what contexts might it make sense to precompile this code ahead of time as opposed to using @jit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Speedup comparison**:\n",
    "* 6.58 times with @jit\n",
    "* 38.98 times with precompiled code - aot.\n",
    "\n",
    "From these results, we can see that the precompiled code has a much higher speedup than the JIT version. This indicates that for this particular simulation application, precompilation provides a more significant performance boost.\n",
    "\n",
    "**Applicable scenarios**:\n",
    "* Just-In-Time (JIT) compilation: better suited for exploratory data analysis and prototyping as it does not require an additional compilation step and can be optimized on-the-fly. When you are developing and testing code, JIT allows you to iterate quickly.\n",
    "\n",
    "* Pre-compile (AOT): better suited for production environments or re-running scenarios. If you have finalized your code logic and need to run the same code multiple times on several different environments or platforms, precompilation can significantly reduce startup time and increase runtime efficiency. Additionally, if you are in an environment that does not allow on-the-fly compilation (such as certain servers or security-restricted environments), precompilation is a good option.\n",
    "\n",
    "In this particular simulation application, it may make more sense to use pre-compiled code if you need to run this simulation over and over again frequently, or if you need to deploy the code to a strict production environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "(3 points) Let’s imagine that this code is still not fast enough and we wish to speed the simulation up further via parallelization. \n",
    "\n",
    "In words, **describe the portions of the above code that are potentially parallelizable**. \n",
    "\n",
    "Then, **calculate the overall theoretical speedup you might expect by parallelizing the code in these spots** (be sure to consider **both Amdahl and Gustafson’s Laws**!). \n",
    "\n",
    "Based on your calculations, **do you expect a linear speedup as you increase parallelism** (e.g. from 1 process to 10 processes to 100 processes)? **Explain your reasoning**. \n",
    "\n",
    "Note: Assume that the generation of eps_mat via sts.norm.rvs() cannot be parallelized and must occur on a single process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13084141699800966"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "# Set model parameters\n",
    "rho = 0.5\n",
    "mu = 3.0\n",
    "sigma = 1.0\n",
    "z_0 = mu\n",
    "\n",
    "# Set simulation parameters, draw all idiosyncratic random shocks,\n",
    "# and create empty containers\n",
    "S = 1000  # Set the number of lives to simulate\n",
    "T = 4160  # Set the number of periods for each simulation\n",
    "np.random.seed(25)\n",
    "eps_mat = sts.norm.rvs(loc=0, scale=sigma, size=(T, S))\n",
    "z_mat = np.zeros((T, S))\n",
    "end = time.perf_counter()\n",
    "interval = end - start\n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865979381443299"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = 0.13/(0.13+0.84)\n",
    "P = 1-S\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans**：\n",
    "\n",
    "1. the portions of the above code that are potentially parallelizable\n",
    "\n",
    "   * the outer loop over the life simulations (`for s_ind in range(S):`). Since each life's simulation is independent and does not require sequential execution, this part is suitable for parallel processing.\n",
    "\n",
    "2. Theoretical Speedup Calculation:\n",
    "\n",
    "   a. **Amdahl's Law**: assume the parallelizable portion is P, then the theoretical maximum speedup is:\n",
    "\n",
    "   $$Speedup = \\frac{1}{S + \\frac{P}{N}} = \\frac{1}{1-P + \\frac{P}{N}}$$\n",
    "\n",
    "   b. **Gustafson’s Law** suggests that with scaled problem sizes, the speedup can be expressed as:\n",
    "\n",
    "   $$Speedup' = N - S \\times (N-1) = P \\times (N-1)$$\n",
    "\n",
    "3. Expectation of Linear Speedup:\n",
    "\n",
    "   a. **According to Amdahl's Law**, increasing the number of parallel processes will not increase the speed indefinitely because there will always be a portion that needs to be executed serially (for example, the generation of `eps_mat`). Therefore, even if you increase from 1 processor to 10 or 100 processors, the speedup will not increase linearly and will eventually encounter a limit.\n",
    "\n",
    "   b. **According to Gustafson’s Law**, if you can increase the size of the problem (e.g., simulate more lives), then you may see a more linear growth in speedup as the number of processors increases. However, in practice, this depends on whether the additional workload can be efficiently distributed and whether the communication overhead between processors does not consume too much time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amdahls(P, N):\n",
    "    S = 1 - P\n",
    "    return 1 / (S + (P / N))\n",
    "\n",
    "def gustafsons(S, N):\n",
    "    return N - S * (N - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amdahl's Law, Speedup N = 1: 1.0\n",
      "Amdahl's Law, Speedup N = 10: 4.533091568449683\n",
      "Amdahl's Law, Speedup N = 100: 7.009673349221925\n",
      "Gustafson's Law, Speedup N = 1: 1.0\n",
      "Gustafson's Law, Speedup N = 10: 8.794\n",
      "Gustafson's Law, Speedup N = 100: 86.734\n"
     ]
    }
   ],
   "source": [
    "P = 0.866\n",
    "S = 1 - P\n",
    "\n",
    "amdahl_speedup_1 = amdahls(P, 1)\n",
    "amdahl_speedup_10 = amdahls(P, 10)\n",
    "amdahl_speedup_100 = amdahls(P, 100)\n",
    "\n",
    "gustafson_speedup_1 = gustafsons(S, 1)\n",
    "gustafson_speedup_10 = gustafsons(S, 10)\n",
    "gustafson_speedup_100 = gustafsons(S, 100)\n",
    "\n",
    "print(\"Amdahl's Law, Speedup N = 1:\", amdahl_speedup_1)\n",
    "print(\"Amdahl's Law, Speedup N = 10:\", amdahl_speedup_10)\n",
    "print(\"Amdahl's Law, Speedup N = 100:\", amdahl_speedup_100)\n",
    "\n",
    "print(\"Gustafson's Law, Speedup N = 1:\", gustafson_speedup_1)\n",
    "print(\"Gustafson's Law, Speedup N = 10:\", gustafson_speedup_10)\n",
    "print(\"Gustafson's Law, Speedup N = 100:\", gustafson_speedup_100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
